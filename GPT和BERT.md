## GPT和BERT

<img src="C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230227200358759.png" alt="image-20230227200358759" style="zoom:150%;" />

Bert的本质目的是认识这个世界

## BERT的意义

从大量无标记数据集中训练得到的深度模型，可以显著提高各项自然语言处理任务的准确性。

## BERT集了哪些大成？

参考了ELMO模型的双向编码思想、借鉴了GPT用Transformer作为特征提取器的思路，采用了word2vec所使用的CBOW方法

## BERT和GPT和ELMo的区别

<img src="C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230227200358759.png" alt="image-20230227200358759" style="zoom:150%;" />

## Bert下游任务改造

