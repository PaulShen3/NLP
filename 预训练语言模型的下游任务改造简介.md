# 预训练语言模型的下游任务改造简介

word2Vec--》是一个神经网络语言模型，其主要任务是生成词向量，也可以说是生成Q矩阵来得到词向量

所以Word2Vec模型是不是预训练模型？

一定是。

什么是预训练？

给出两个任务A和任务B，任务A已经做出了模型A，任务B无法解决(通过使用模型A加快任务的解决)

给你一个NLP里面的任务，给一个问题X(Pa+ul)，给出一个回答Y(handsome)

![image-20230226202656423](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230226202656423.png)

预训练语言模型终于出来(给出一句话，我们先使用独热编码（一一对应的一种表查询，无法微调只能冻结），再使用word2vec预训练好的Q矩阵直接得到词向量，然后进行接下来的任务)

1.冻结：可以不改变Q矩阵

2.微调：随着任务的改变，改变Q矩阵

