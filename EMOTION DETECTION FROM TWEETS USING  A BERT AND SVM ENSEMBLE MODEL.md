# EMOTION DETECTION FROM TWEETS USING  A BERT AND SVM ENSEMBLE MODEL 

摘要：

自动识别Twitter数据中表达的情绪具有广泛的应用。我们通过向包含四种情绪(恐惧、悲伤、喜悦和愤怒)的基准数据集添加一个中性类来创建一个平衡良好的数据集。在这个扩展数据集上，我们研究了支持向量机(SVM)和变压器的双向编码器表示(BERT)用于情感识别的使用。本文结合BERT和SVM两种模型，提出了一种新的集成模型。实验表明，该模型在推文情感识别上的准确率达到了0.91。

introduction：

情绪检测是情感分析的一个子领域，主要研究从文本数据中检测作者的情绪。两者之间的主要区别在于，情感分析试图将文本划分为积极或消极，而情绪检测试图识别作者的确切情绪，如快乐、悲伤、恐惧等。对于自然语言处理系统来说，推文的情感分析是一项非常具有挑战性的任务。与传统文本不同，tweet是非常短的消息，包含拼写错误、俚语、缩略形式、短语缩写和表达性加长[1]。自动识别Twitter数据中表达的情绪具有广泛的应用，例如了解消费者对产品[2]的看法，股票市场预测[3]，抑郁症检测[4]，检测欺凌事件[5]，以及识别恐怖威胁[6]。本文的贡献可以概括为以下几点。我们提出了WASSA数据集[7]的改进版本，用于情感检测任务，该数据集是通过平衡和添加一个新类(中性类)获得的。我们的实验结果3表明，与其他机器学习分类器相比，SVM提供了最好的结果。进一步，我们微调了三个BERT版本，并在我们的数据集上展示它们的性能。最后，我们介绍了一种新的集成模型，它结合了BERT和SVM模型，并获得了最先进的结果。

文献综述:

Wang等人利用情感标签自动创建了一个包含约250万条推文的大型数据集。他们应用了两种不同的分类器，逻辑回归和Naïve贝叶斯，来探索各种特征(如n-grams、情感词汇和词性信息)在情绪识别任务中的有效性。最高准确度为0.6557。

Mohammad[9]使用标签自动创建了大约21000个带有情感标签的推文语料库。他使用了二进制支持向量机，Ekman[10]的六种基本情绪中的每一种，并使用unigrams和biggram的存在或不存在作为二进制特征。二元分类器能够预测情绪，f1得分为0.499。

Janssens等[11]研究了使用弱标签与强标签对由341,931条推文组成的语料库的情感识别的影响。弱标签是通过使用推文的标签创建的，强标签是通过使用众包创建的。结合ngrams和TF-IDF (Term Frequency- inverse Document Frequency, Term Frequency- inverse Document Frequency)提取的特征应用于随机梯度下降、支持向量机(SVM)、Naïve贝叶斯(Bayes)、最近质心(Nearest Centroid)和Ridge 5种分类算法。结果显示，使用弱标记时，F1score仅下降9.25%

Abdul-Mageed和Ungar[12]使用远程监督自动构建了一个包含约160万条标记推文的大型数据集，然后训练门控循环神经网络进行细粒度情绪检测。他们在24种细粒度情绪上的平均准确度为0.8758.Felbo等人[13]采用长短期记忆模型的变体对16亿条推文组成的数据集进行表情符号预测。然后，他们对预先训练的模型进行了微调，以检测情绪、情绪和讽刺.使用他们预先训练的DeepMoji模型，情绪分析中获得的最高平均f1得分为0.61。

Chiorrini等人[14]研究了transformer (BERT)[15]的双向编码器表示用于Twitter数据的情感分析和情感识别。他们在情绪识别任务上达到了0.90的准确性。

准备方法：

数据集：

用于训练和评估推文中的情绪的数据集部分提取自WASSA数据集，该数据集提供给主观性、情感和社交媒体分析计算方法研讨会(WASSA-2017)[7]的参与者。我们针对恐惧、悲伤、喜悦和愤怒这四种情绪分别提取了1500条推文，而没有考虑包含情绪强度的数据。在这四个类的旁边，我们增加了一个额外的1500个中性推文的类，正如[16]中所示，在分类过程中拥有一个中性类是很重要的，因为这样神经网络就不必将未知的情绪分类到已学习的情绪类别之一。

中立推文从CrowdFlower4中提取。

我们以这种方式划分数据集的原因是拥有一个良好平衡的数据集的重要性。一个平衡良好的数据集每个类[17]包含相同数量的样本。这确保了模型在分类过程中不会偏向于较大的类。

SVM模型的预处理阶段涉及传统的机器学习预处理操作:表情符号到单词转换、Unicode到ASCII转换、停止单词过滤、句子标记化和向量化以及标签编码。我们首先对推文进行预处理，从推文中去除不必要的单词和人工元素(用户名、链接、标签符号)，然后使用Demoji Python库5 (Unicode表情符号)和从Wikipedia6(西方风格的表情符号)中提取的含义，将表情符号翻译成它们的含义。使用表情符号到单词的转换是因为表情符号可能与检测推文中的情绪有关，因为它们经常用于文本消息中，以便更好地传达情感[18]。

**Unicode到ASCII的转换被认为很重要，因为ASCII字符集比Unicode字符集更小，因此计算时间会减少，因为字数也会减少，这可能会导致性能提升。**

数据集中的停止词过滤已被证明可以提高性能和计算速度[19]，因此我们使用nltk的停止词列表来完成这项任务。阻塞是改进模型性能的另一种方法通过将衍生词简化为一个叫做stem的语法词根。在本文中，我们使用了nltk的Snowball stemmer7。

**为了将每条推文转换为数字向量，我们使用了标记化和术语频率乘以逆文档频率(tf-idf)。Tf-idf[20]试图通过计算两个统计数据来估计数据集中令牌的重要性:术语频率，这意味着特定术语在推文中出现的频率，以及用于测量特定术语相对于语料库中所有推文提供多少信息的逆文档频率。tf-idf的最终结果是两个频率的乘积。**

为了将数据提供给模型，推文和标签都必须进行预处理。标签编码是通过使用数字标签编码器8来实现的，它为每个情感类分配一个唯一的数字。

**在构建支持向量机模型时，选用径向基函数(RBF)核。这个决定是基于这样一个事实:与其他内核相比，它的非线性将数据映射到一个更高维度的空间。它比其他内核[21]具有更少的超参数和数值困难。正则化因子(C)经经验设置为1。**



3.3 BERT Model 

本文分析了BERT的三个版本，香草BERT，这是第一个版本[15]，RoBERTa(稳健优化BERT方法)，这是BERT[22]的优化版本，BERTweet[23]，这是一个在推特上预训练的RoBERTa模型。

对于BERT版本，使用了不同的预处理方法。链接和用户名被删除了，因为这些被认为是不重要的，保留它们可能会导致一个有偏见的模型。在此基础上，采用BERT特定预处理，包括:

•词标记化。每个句子被分成构成它的单词，并分配一个唯一的单词标识符。BERT使用WordPiece标记器。

•填充。每个句子都被填充到相同数量的符号。

•建立注意力面具。注意掩码将使模型能够区分填充标记和原始标记。

•添加BERT令牌。这些令牌是CLS, SEP, PAD, UKN, EOS，并且是使用蒙面语言建模[15]预训练模型的一部分。



标签以与SVM模型相同的方式编码，使用数字标签编码器。为了对情绪检测任务的三个BERT版本进行微调，我们为RoBERTa、BERTweet和vanilla BERT选择了基本的case模型。

此外，BERT模型使用了一个池输出，利用了第一个令牌[CLS]令牌的位置。一个汇集的输出由一个大小为768的词嵌入向量表示，它表示[CLS]标记的词嵌入。这通常在对整个序列进行分类时进行，而不是对单个标记进行分类。在此输出之上增加一个密集层，其输入维数为768，输出维数等于情感类的数量。为了获得概率，**使用了LogSoftmax9激活函数，因为它提供了比Softmax更好的数值稳定性。**在训练过程中，添加一个失失率为30%的dropout层以缓解过拟合。这种微调方法的概述可以在图1中看到。

![image-20230303193226800](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193226800.png)



我们选择的损失函数为Negative Log Likelihood loss10，因为它可以和LogSoftmax一起使用来代替Categorical Cross Entropy11。选择权重衰减的Adam优化器:学习率设置为52 10−，并使用没有热身步骤的线性调度器，以便随着训练的进行动态地改变学习率。这些配置与[15]中显示的一致。在训练过程中，使用最大范数为1的梯度范数裁剪，以降低消失或爆炸梯度的出现概率。



## BERT与SVM集成模型

集成模型在历史上被用于为各种机器学习分类问题[24]产生最先进的结果。集成模型提供了更好的结果，因为在产生输出时考虑了每个单独模型带来的优势。当组合模型具有不同的架构时，这通常工作得最好，因为这确保了每个模型学习查看训练数据[24]的不同方面。为了构建提议的集成模型，我们结合了BERTweet模型(因为这个版本似乎提供了最好的结果)和SVM模型。每个模型在做出预测之前都会使用特定的预处理。

为了获得每个情感类别的概率，集成模型计算从两个模型获得的对数概率向量的和。由于对数概率在区间(，0 -)中有值，当将两个概率向量相加时，坏结果会变得更糟，而好结果不会受到影响，因为它们更接近于0。

集成模型工作流程如图2所示。![image-20230303193210530](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193210530.png)

 ## 实验结果

为了深入了解我们提出的模型，首先我们检查在第3节中介绍的数据集上性能最好的传统机器学习模型。然后我们比较了BERT的三个版本，最后我们展示了集成模型的结果。

所有模型都使用相同的数据训练-验证-测试比例进行训练，即:每种情绪的训练样本为1200个，验证样本为150个，测试样本为150个。

从我们的结果来看，与其他机器学习分类器(如多项Naïve Bayes[25]和高斯Naïve Bayes[26])相比，SVM分类器似乎在情感检测任务中提供了最好的结果，如表1所示。![image-20230303193356998](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193356998.png)

为了训练贝叶斯模型，使用了与支持向量机模型相同的预处理技术。对于多项式型Naïve贝叶斯选择一个附加平滑参数1，对于高斯型Naïve贝叶斯选择一个平滑变量0.5。这些值是根据经验选择的。然后将模型拟合到训练集上进行测试。结果表明，多项式Naïve贝叶斯是两种模型中较好的选择，准确率为0.80。在训练过程中，SVM模型在预处理阶段之后被拟合到训练集上。在验证集上，该模型获得了0.87的准确性评分。为了确保我们的模型在以前未见过的数据上表现良好，模型在测试集上进行了测试。在测试集上的准确性得分为0.84，这表明模型是可靠的。为了更好地理解模型在检测每种情绪时的表现，在测试集上计算了一个混淆矩阵，如图3所示。![image-20230303193416508](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193416508.png)

结果表明，该模型在识别中性情绪时表现最差，而在识别愤怒情绪时表现最好。这可能是由于中性类具有与所有其他类不同的令牌分布。这种行为已经在多项Naïve贝叶斯分类器中被注意到。



## 4.2提出的BERT模型的结果

为了训练所提出的BERT模型，使用了5个epoch的训练时间和16个batch size。训练时间不需要很长，因为模型经过预训练后，在相对较少的epoch后就会达到最大精度。

对于普通的BERT模型，在预处理阶段将推文填充为85个令牌的大小，这是在所提供的数据集中找到的最大大小。对于验证集，模型的精度为0.89，对于测试集，模型的精度为0.87。这表明，与SVM模型相比，香草BERT模型提供了更好的结果。

对于RoBERTa模型，推文在预处理阶段被填充到170个令牌的大小。这种大小的增加是由于RoBERTa tokenizer将在表情符号之前添加额外的空格。该模型对测试集和验证集的准确性为0.87。这表明，与普通BERT模型相比，RoBERTa模型并没有带来任何额外的改进。

对于BERTweet模型，推文的大小被填充为90个令牌，这是模型应用其特定预处理后在所呈现的数据集中发现的最大大小。对于验证集，模型的精度为0.89，对于测试集，模型的精度为0.89。测试集上的混淆矩阵如图4所示。这表明BERTweet的性能略好于普通版本。因此，选择此BERT版本构建BERT- svm集成模型。表4中可以观察到所提供数据集上BERT版本之间的比较。![image-20230303193450102](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193450102.png)

![image-20230303193457955](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193457955.png)

## 4.3集成模型的结果

为了评估集成模型的性能，SVM和BERTweet模型都计算了验证集和测试集的日志概率向量。然后，将两个模型的向量进行相加，得到集成模型的结果。一条推文的预测情感类别将是在相应的概率向量中发现的概率最高的类别。集成模型在验证集和测试集上的准确性得分均为0.91。从图5的混淆矩阵可以看出，该模型在所有类别上都表现良好，中性情绪类别的准确率最低，为0.84。

## 4.4情绪检测模型比较

从表6可以看出，使用集成模型获得了最好的结果。该模型优于SVM和BERT模型，精度为0.91。![image-20230303193550042](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193550042.png)

这一精度足以考虑所提出的模型的现状。然而，与在初始数据集上训练的相同模型相比，在没有额外的中性推文的情况下，准确率略低，为0.94。

![image-20230303193610003](C:\Users\Jay Shen\AppData\Roaming\Typora\typora-user-images\image-20230303193610003.png)

值得一提的是，在扩展数据集上训练的拟议模型能够检测何时推文没有传达任何情感，这可能在模型的现实生活使用中被证明是有用的。

# Conclusion

从我们的结果中，我们可以得出结论，与迄今为止研究的其他方法相比，使用集成模型进行情绪检测任务提供了最好的结果。与[14]相比，我们在同一数据集上的结果略好，准确率为0.94。

在支持向量机分类器的情况下，愤怒类和在BERTweet模型的情况下，喜悦类分别获得了最高的f1得分。SVM和BERTweet模型结合在一起时似乎可以改善彼此的结果，这在考虑其他集成模型的未来发展时是一个重要的发现。对于未来的研究，集成模型可以通过研究具有更多参数的BERT版本(如大版本)来改进，这可能会带来更好的结果。





